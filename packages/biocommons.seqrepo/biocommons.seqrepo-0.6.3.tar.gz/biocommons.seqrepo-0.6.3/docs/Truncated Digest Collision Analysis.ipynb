{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Truncated Digest Timing and Collision Analysis\n",
    "\n",
    "SeqRepo assigns identifiers to sequences based on a SHA-512 digest, truncated to 24 bytes (192 bits), and `base64url` [8] encoded. This notebook discusses the choice of SHA-512 over other digest methods and the choice of truncation length.  This scheme is also used in the [GA4GH Computed Identifiers](https://vr-spec.readthedocs.io/en/1.0/impl-guide/computed_identifiers.html) and by the [RefGet reference sequence protocol](http://samtools.github.io/hts-specs/refget.html#checksum-choice).\n",
    "\n",
    "Source: Reece Hart, [CC-BY](https://creativecommons.org/licenses/by/4.0/)\n",
    "\n",
    "\n",
    "## Conclusions\n",
    "\n",
    "* The computational time for SHA-512 is similar to that of other digest methods on 64-bit CPUs, and is believed to be at least as cryptographically robust as other methods tested.\n",
    "* 24 bytes (192 bits) of digest should be ample. For example, the probability of collision for a 24-byte digest over 1e18 messages is less than 1e-21."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "import math\n",
    "import timeit\n",
    "\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "from ga4gh.vr.extras.utils import _format_time\n",
    "\n",
    "algorithms = {'sha512', 'sha1', 'sha256', 'md5', 'sha224', 'sha384'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Digest Timing\n",
    "\n",
    "This section provides a rationale for the selection of SHA-512 as the basis for the Truncated Digest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blob(l):\n",
    "    \"\"\"return binary blob of length l (POSIX only)\"\"\"\n",
    "    return open(\"/dev/urandom\", \"rb\").read(l)\n",
    "\n",
    "def digest(alg, blob):\n",
    "    md = hashlib.new(alg)\n",
    "    md.update(blob)\n",
    "    return md.digest()\n",
    "\n",
    "def magic_run1(alg, blob):\n",
    "    t = %timeit -o digest(alg, blob)\n",
    "    return t\n",
    "\n",
    "def magic_tfmt(t):\n",
    "    \"\"\"format TimeitResult for table\"\"\"\n",
    "    return \"{a} ± {s} ([{b}, {w}])\".format(\n",
    "        a = _format_time(t.average),\n",
    "        s = _format_time(t.stdev),\n",
    "        b = _format_time(t.best),\n",
    "        w = _format_time(t.worst),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "blob_lengths = [100, 1000, 10000, 100000, 1000000]\n",
    "blobs = [blob(l) for l in blob_lengths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "algorithm|100|1000|10000|100000|1000000\n",
       "-|-|-|-|-|-\n",
       "md5|1.67 ms|3.49 ms|18.7 ms|164 ms|1.57 s\n",
       "sha1|887 us|1.81 ms|11.6 ms|131 ms|1.09 s\n",
       "sha224|1.36 ms|3.25 ms|25.6 ms|243 ms|2.42 s\n",
       "sha256|1.02 ms|3.14 ms|24.3 ms|240 ms|2.36 s\n",
       "sha384|1.08 ms|2.47 ms|17.4 ms|155 ms|1.55 s\n",
       "sha512|1 ms|2.46 ms|16.7 ms|153 ms|1.67 s"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "table_rows = []\n",
    "table_rows += [[\"algorithm\"] + list(map(str,blob_lengths))]\n",
    "table_rows += [[\"-\"] * len(table_rows[0])]\n",
    "for alg in sorted(algorithms):\n",
    "    r = [alg]\n",
    "    for i in range(len(blobs)):\n",
    "        blob = blobs[i]\n",
    "        t = timeit.timeit(stmt='digest(alg, blob)', setup='from __main__ import alg, blob, digest', number=1000)\n",
    "        r += [_format_time(t)]\n",
    "    table_rows += [r]\n",
    "table = \"\\n\".join([\"|\".join(map(str,row)) for row in table_rows])\n",
    "display(Markdown(table))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion: SHA-512 computational time is similar to that of other digest methods.**\n",
    "\n",
    "This is result was not expected initially. On further research, there is a clear explanation: The SHA-2 series of digests (which includes SHA-224, SHA-256, SHA-384, and SHA-512) is defined using 64-bit operations. When an implementation is optimized for 64-bit systems (as used for these timings), the number of cycles is essentially halved when compared to 32-bit systems and digests that use 32-bit operations. SHA-2 digests are indeed much slower than SHA-1 and MD5 on 32-bit systems, but such legacy platforms is not relevant to the Truncated Digest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Collision Analysis\n",
    "\n",
    "Our question: **For a hash function that generates digests of length b (bits) and a corpus of m messages, what is the probability p that there exists at least one collision?** This is the so-called Birthday Problem [6].\n",
    "\n",
    "Because analyzing digest collision probabilities typically involve choices of mathematical approximations, multiple \"answers\" appear online. This section provides a quick review of prior work and extends these discussions by focusing the choice of digest length for a desired collision probability and corpus size.\n",
    "\n",
    "Throughout the following, we'll use these variables:\n",
    "\n",
    "  * $P$ = Probability of collision\n",
    "  * $P'$ = Probability of no collision\n",
    "  * $b$ = digest size, in bits\n",
    "  * $s$ = digest space size, $s = 2^b$\n",
    "  * $m$ = number of messages in corpus\n",
    "\n",
    "The length of individual messages is irrelevant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Background: The Birthday Problem\n",
    "\n",
    "Directly computing the probability of one or more collisions, $P$, in a corpus is difficult. Instead, we first seek to solve for $P'$, the probability that a collision does not exist (i.e., that the digests are unique).  Because are only two outcomes, $P + P' = 1$ or, equivalently, $P = 1 - P'$. \n",
    "\n",
    "For a corpus of size $m=1$, the probabability that the digests of all $m=1$ messages are unique is (trivially) 1:\n",
    "\n",
    "$$P' = s/s = 1$$\n",
    "\n",
    "because there are $s$ ways to choose the first digest from among $s$ possible values without a collision.\n",
    "\n",
    "For a corpus of size $m=2$, the probabability that the digests of all $m=2$ messages are unique is:\n",
    "\n",
    "$$P' = 1 \\times (\\frac{s-1}{s})$$\n",
    "\n",
    "because there are $s-1$ ways to choose the second digest from among $s$ possible values without a collision.\n",
    "\n",
    "Continuing this logic, we have:\n",
    "\n",
    "$$P' = \\prod\\nolimits_{i=0}^{m-1} \\frac{(s-i)}{s}$$\n",
    "\n",
    "or, equivalently,\n",
    "\n",
    "$$P' = \\frac{s!}{s^m \\cdot (s-m)!}$$\n",
    "\n",
    "When the size of the corpus becomes greater than the size of the digest space, the probability of uniques is zero by the pigeonhole principle. Formally, the above equation becomes:\n",
    "\n",
    "$$\n",
    "P' = \\left\\{\n",
    "        \\begin{array}{ll}\n",
    "            1    &    \\text{if }m = 0 \\\\\n",
    "            \\prod\\nolimits_{i=0}^{m-1} \\frac{(s-i)}{s}    &    \\text{if }1 \\le m\\le s\\\\\n",
    "            0    &    \\text{if }m \\gt s\n",
    "        \\end{array}\n",
    "     \\right.\n",
    "$$\n",
    "\n",
    "For the remainder of this section, we'll focus on the case where $1 \\le m \\ll s$. In addition, notice that the brute force computation is not feasible in practice because $m$ and $s$ will be very large (both $\\gg 2^9$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approximation #1: Taylor approximation of terms of P'\n",
    "\n",
    "The Taylor series expansion of the exponential function is\n",
    "\n",
    "$$e^x = 1 + x + \\frac{x^2}{2!} + \\frac{x^3}{3!} + ...$$\n",
    "\n",
    "For $|x| \\ll 1$, the expansion is dominated by the first terms and therecore $e^x \\approx 1 + x$.\n",
    "\n",
    "In the above expression for $P'$, note that the product term $(s-i)/s$ is equivalent to $1-i/s$. Combining this with the Taylor expansion, where $x = -i/s$ (⇒ $m \\ll s$):\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "P' & \\approx \\prod\\nolimits_{i=0}^{m-1} e^{-i/s} \\\\\n",
    "   & = e^{-m(m-1)/2s}\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "(The latter equivalence comes from converting the product of exponents to a single exponent of a summation of $-i/s$ terms, factoring out $1/s$, and using the series sum equivalence $\\sum\\nolimits_{j=0}^{n} j = n(n+1)/2$ for $n\\ge0$.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Appriximation #2: Taylor approximation of P'\n",
    "\n",
    "The above result for $P'$ is also amenable to Taylor approximation. Setting $x = -m(m-1)/2s$, we continue from the previous derivation:\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "P' & \\approx e^{-(m(m-1)/2s} \\\\\n",
    "   & \\approx 1 + \\frac{-m(m-1)}{2s}\n",
    "\\end{split}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approximation #3: Square approximation\n",
    "\n",
    "For large $m$, we can approximate $m(m-1)$ as $m^2$ to yield $$P' \\approx 1-m^2/2s$$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary of equations\n",
    "\n",
    "We may now summarize equations to approximate the probability of digest collisions.\n",
    "\n",
    "| Method | Probability of uniqueness<br/>($P'$) | Probability of collision<br/>($P=1-P'$) | Assumptions | Source/Comparison |\n",
    "|----------------|----------------|----------------|----------------|----------------|\n",
    "| exact | $\\prod\\nolimits_{i=0}^{m-1} \\frac{(s-i)}{s}$ | $1-P'$ | $1 \\le m\\le s$ | [6] |\n",
    "| Taylor approximation #1 | $e^{-m(m-1)/2s}$ | $1-P'$ | $m \\ll s$ | [6] |\n",
    "| Taylor approximation #2 | $1 - \\frac{m(m-1)}{2s}$ | $\\frac{m(m-1)}{2s}$ | (same) | [6] |\n",
    "| Large square approximation | $1 - \\frac{m^2}{2s}$ | $\\frac{m^2}{2s}$ | (same) | [5]<br/>(where $s=2^n$) |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Choosing a digest size\n",
    "\n",
    "Now, we turn the problem around: **What digest length $b$ corresponds with a collision probability less than $P$ for $m$ messages?**\n",
    "\n",
    "From the above summary, we have $P = m^2 / 2s$ for $m \\ll s$. Rewriting with $s=2^b$, we have the probability of a collision using $b$ bits with $m$ messages (sequences) is:\n",
    "\n",
    "$$P(b, m) = m^2 / 2^{b+1}$$\n",
    "\n",
    "Note that the collision probability depends on the number of messages, but not their size.\n",
    "\n",
    "Solving for the number of messages (not used further in this analysis):\n",
    "\n",
    "$$m(b, P) = \\sqrt{P * 2^{b+1}}$$\n",
    "\n",
    "Solving for the minimum number of *bits* $b$ as a function of an expected number of sequences $m$ and a desired tolerance for collisions of $P$:\n",
    "\n",
    "$$b(m, P) = \\log_2{\\left(\\frac{m^2}{P}\\right)} - 1$$\n",
    "\n",
    "This equation is derived from equations that assume that $m \\ll s$, where $s = 2^b$. When computing $b(m,P)$, we'll require that $m/s \\le 10^{-3}$ as follows:\n",
    "\n",
    "$$m/s \\le 10^{-3}$$\n",
    "\n",
    "is approximately equivalent to:\n",
    "\n",
    "$$m/2^b \\le 2^{-5}$$\n",
    "\n",
    "$$m \\le 2^{b-5}$$\n",
    "\n",
    "$$log_2 m \\le b-5$$\n",
    "\n",
    "$$b \\ge 5 + log_2 m$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def b2B3(b):\n",
    "    \"\"\"Convert bits b to Bytes, rounded up modulo 3\n",
    "\n",
    "    We report modulo 3 because the intent will be to use Base64 encoding, which is\n",
    "    most efficient when inputs have a byte length modulo 3. (Otherwise, the resulting\n",
    "    string is padded with characters that provide no information.)\n",
    "    \n",
    "    \"\"\"\n",
    "    return math.ceil(b/8/3) * 3\n",
    "    \n",
    "def B(P, m):\n",
    "    \"\"\"return the number of bits needed to achieve a collision probability\n",
    "    P for m messages\n",
    "\n",
    "    Assumes m << 2^b.\n",
    "    \n",
    "    \"\"\"\n",
    "    b = math.log2(m**2 / P) - 1\n",
    "    if b < 5 + math.log2(m):\n",
    "        return \"-\"\n",
    "    return b2B3(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_bins = [1E6, 1E9, 1E12, 1E15, 1E18, 1E21, 1E24, 1E30]\n",
    "P_bins = [1E-30, 1E-27, 1E-24, 1E-21, 1E-18, 1E-15, 1E-12, 1E-9, 1E-6, 1E-3, 0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### digest length (bytes) required for expected collision probability $P$ over $m$ messages \n",
       "#m|P<=1e-30|P<=1e-27|P<=1e-24|P<=1e-21|P<=1e-18|P<=1e-15|P<=1e-12|P<=1e-09|P<=1e-06|P<=0.001|P<=0.5\n",
       "-|-|-|-|-|-|-|-|-|-|-|-\n",
       "1e+06|18|18|15|15|15|12|12|9|9|9|6\n",
       "1e+09|21|21|18|18|15|15|15|12|12|9|9\n",
       "1e+12|24|24|21|21|18|18|15|15|15|12|12\n",
       "1e+15|27|24|24|24|21|21|18|18|15|15|15\n",
       "1e+18|30|27|27|24|24|24|21|21|18|18|15\n",
       "1e+21|30|30|30|27|27|24|24|24|21|21|18\n",
       "1e+24|33|33|30|30|30|27|27|24|24|24|21\n",
       "1e+30|39|39|36|36|33|33|30|30|30|27|27"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "table_rows = []\n",
    "table_rows += [[\"#m\"] + [\"P<={P}\".format(P=P) for P in P_bins]]\n",
    "table_rows += [[\"-\"] * len(table_rows[0])]\n",
    "for n_m in m_bins:\n",
    "    table_rows += [[\"{:g}\".format(n_m)] + [B(P, n_m) for P in P_bins]]\n",
    "table = \"\\n\".join([\"|\".join(map(str,row)) for row in table_rows])\n",
    "table_header = \"### digest length (bytes) required for expected collision probability $P$ over $m$ messages \\n\"\n",
    "display(Markdown(table_header +  table))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## References\n",
    "\n",
    "- [1] http://nvlpubs.nist.gov/nistpubs/FIPS/NIST.FIPS.180-4.pdf  \n",
    "- [2] https://tools.ietf.org/html/rfc3548#section-4  \n",
    "- [3] http://stackoverflow.com/a/4014407/342839  \n",
    "- [4] http://stackoverflow.com/a/22029380/342839  \n",
    "- [5] http://preshing.com/20110504/hash-collision-probabilities/  \n",
    "- [6] https://en.wikipedia.org/wiki/Birthday_problem\n",
    "- [7] https://en.wikipedia.org/wiki/Birthday_attack\n",
    "- [8] https://tools.ietf.org/html/rfc4648#section-5\n",
    "\n",
    "\n",
    "## Acknowledgements\n",
    "Thanks to Bob Freimuth for identifying an error in a superscript that caused collision probabilities to be underestimated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

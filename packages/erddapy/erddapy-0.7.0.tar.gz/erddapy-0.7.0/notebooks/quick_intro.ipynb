{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick introduction\n",
    "\n",
    "\n",
    "erddapy can be installed with conda\n",
    "\n",
    "\n",
    "```shell\n",
    "conda install --channel conda-forge erddapy\n",
    "```\n",
    "\n",
    " or pip\n",
    "\n",
    "```shell\n",
    "pip install erddapy\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to instantiate the ERDDAP URL constructor for a server.\n",
    "In this example we will use [https://gliders.ioos.us/erddap](https://gliders.ioos.us/erddap/index.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from erddapy import ERDDAP\n",
    "\n",
    "\n",
    "e = ERDDAP(\n",
    "    server=\"https://gliders.ioos.us/erddap\",\n",
    "    protocol=\"tabledap\",\n",
    "    response=\"csv\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can populate the object a dataset id, variables of interest, and \n",
    "its constraints. We can download the csvp response with the `.to_pandas` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e.dataset_id = \"whoi_406-20160902T1700\"\n",
    "\n",
    "e.variables = [\n",
    "    \"depth\",\n",
    "    \"latitude\",\n",
    "    \"longitude\",\n",
    "    \"salinity\",\n",
    "    \"temperature\",\n",
    "    \"time\",\n",
    "]\n",
    "\n",
    "e.constraints = {\n",
    "    \"time>=\": \"2016-07-10T00:00:00Z\",\n",
    "    \"time<=\": \"2017-02-10T00:00:00Z\",\n",
    "    \"latitude>=\": 38.0,\n",
    "    \"latitude<=\": 41.0,\n",
    "    \"longitude>=\": -72.0,\n",
    "    \"longitude<=\": -69.0,\n",
    "}\n",
    "\n",
    "\n",
    "df = e.to_pandas(\n",
    "    index_col=\"time (UTC)\",\n",
    "    parse_dates=True,\n",
    ").dropna()\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(17, 2))\n",
    "cs = ax.scatter(\n",
    "    df.index,\n",
    "    df[\"depth (m)\"],\n",
    "    s=15,\n",
    "    c=df[\"temperature (Celsius)\"],\n",
    "    marker=\"o\",\n",
    "    edgecolor=\"none\"\n",
    ")\n",
    "\n",
    "ax.invert_yaxis()\n",
    "ax.set_xlim(df.index[0], df.index[-1])\n",
    "xfmt = mdates.DateFormatter(\"%H:%Mh\\n%d-%b\")\n",
    "ax.xaxis.set_major_formatter(xfmt)\n",
    "\n",
    "cbar = fig.colorbar(cs, orientation=\"vertical\", extend=\"both\")\n",
    "cbar.ax.set_ylabel(\"Temperature ($^\\circ$C)\")\n",
    "ax.set_ylabel(\"Depth (m)\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Longer introduction\n",
    "\n",
    "Let's explore the methods and attributes available in the ERDDAP object?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from erddapy import ERDDAP\n",
    "\n",
    "\n",
    "e = ERDDAP(server=\"https://gliders.ioos.us/erddap\")\n",
    "\n",
    "[method for method in dir(e) if not method.startswith(\"_\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the *get_<methods>* will return a valid ERDDAP URL for the requested response and options. For example, a search for all datasets available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = e.get_search_url(search_for=\"all\", response=\"csv\")\n",
    "\n",
    "print(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many responses available, see the docs for [griddap](https://coastwatch.pfeg.noaa.gov/erddap/griddap/documentation.html) and\n",
    "[tabledap](https://coastwatch.pfeg.noaa.gov/erddap/tabledap/documentation.html) respectively.\n",
    "The most useful ones for Pythonistas are the .csv and .nc that can be read with pandas and netCDF4-python respectively.\n",
    "\n",
    "Let's load the csv response directly with pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "df = pd.read_csv(url)\n",
    "print(\n",
    "    f'We have {len(set(df[\"tabledap\"].dropna()))} '\n",
    "    f'tabledap, {len(set(df[\"griddap\"].dropna()))} '\n",
    "    f'griddap, and {len(set(df[\"wms\"].dropna()))} wms endpoints.'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can refine our search by providing some constraints."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's narrow the search area, time span, and look for **sea_water_temperature** ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from erddapy.utilities import show_iframe\n",
    "\n",
    "\n",
    "kw = {\n",
    "    \"standard_name\": \"sea_water_temperature\",\n",
    "    \"min_lon\": -72.0,\n",
    "    \"max_lon\": -69.0,\n",
    "    \"min_lat\": 38.0,\n",
    "    \"max_lat\": 41.0,\n",
    "    \"min_time\": \"2016-07-10T00:00:00Z\",\n",
    "    \"max_time\": \"2017-02-10T00:00:00Z\",\n",
    "    \"cdm_data_type\": \"trajectoryprofile\"\n",
    "}\n",
    "\n",
    "\n",
    "search_url = e.get_search_url(response=\"html\", **kw)\n",
    "show_iframe(search_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the search form was populated with the constraints we provided.\n",
    "\n",
    "Changing the response from html to csv we load it in a data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_url = e.get_search_url(response=\"csv\", **kw)\n",
    "search = pd.read_csv(search_url)\n",
    "gliders = search[\"Dataset ID\"].values\n",
    "\n",
    "gliders_list = \"\\n\".join(gliders)\n",
    "print(f\"Found {len(gliders)} Glider Datasets:\\n{gliders_list}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we know the Dataset ID we can explore their metadata with the *get_info_url* method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "glider = gliders[-1]\n",
    "\n",
    "info_url = e.get_info_url(dataset_id=glider, response=\"html\")\n",
    "\n",
    "show_iframe(src=info_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can manipulate the metadata and find the variables that have the *cdm_profile_variables* attribute using the csv response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "info_url = e.get_info_url(dataset_id=glider, response='csv')\n",
    "\n",
    "info = pd.read_csv(info_url)\n",
    "info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\".join(info.loc[info[\"Attribute Name\"] == \"cdm_profile_variables\", \"Value\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selecting variables by theirs attributes is such a common operation that erddapy brings its own method to simplify this task.\n",
    "\n",
    "The *get_var_by_attr* method was inspired by netCDF4-python's *get_variables_by_attributes*. However, because erddapy is operating on remote serves, it will return the variable names instead of the actual variables.\n",
    "\n",
    "Here we check what is/are the variable(s) associated with the *standard_name* used in the search.\n",
    "\n",
    "Note that *get_var_by_attr* caches the last response in case the user needs to make multiple requests.\n",
    "(See the execution times below.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# First one, slow.\n",
    "e.get_var_by_attr(\n",
    "    dataset_id=\"whoi_406-20160902T1700\",\n",
    "    standard_name=\"sea_water_temperature\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Second one on the same glider, a little bit faster.\n",
    "e.get_var_by_attr(\n",
    "    dataset_id=\"whoi_406-20160902T1700\",\n",
    "    standard_name=\"sea_water_practical_salinity\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# New one, slow again.\n",
    "e.get_var_by_attr(\n",
    "    dataset_id=\"cp_336-20170116T1254\",\n",
    "    standard_name=\"sea_water_practical_salinity\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way to browse datasets is via the *categorize* URL. In the example below we can get all the *standard_names* available in the dataset with a single request."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = e.get_categorize_url(\n",
    "    categorize_by=\"standard_name\",\n",
    "    response=\"csv\"\n",
    ")\n",
    "\n",
    "pd.read_csv(url)[\"Category\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also pass a **value** to filter the categorize results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = e.get_categorize_url(\n",
    "    categorize_by=\"institution\",\n",
    "    value=\"woods_hole_oceanographic_institution\",\n",
    "    response=\"csv\"\n",
    ")\n",
    "\n",
    "df = pd.read_csv(url)\n",
    "whoi_gliders = df.loc[~df[\"tabledap\"].isnull(), \"Dataset ID\"].tolist()\n",
    "whoi_gliders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a map of all the gliders tracks from WHOI.\n",
    "\n",
    "(We are downloading a lot of data! Note that we will use [joblib](https://joblib.readthedocs.io/en/latest/) to parallelize the for loop and get the data faster.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "\n",
    "\n",
    "def request_whoi(dataset_id):\n",
    "    e.constraints = None\n",
    "    e.protocol = \"tabledap\"\n",
    "    e.variables = [\"longitude\", \"latitude\", \"temperature\", \"salinity\"]\n",
    "    e.dataset_id = dataset_id\n",
    "    # Drop units in the first line and NaNs.\n",
    "    df = e.to_pandas(response=\"csv\", skiprows=(1,)).dropna()\n",
    "    return (dataset_id, df)\n",
    "        \n",
    "\n",
    "num_cores = multiprocessing.cpu_count()\n",
    "downloads = Parallel(n_jobs=num_cores)(\n",
    "    delayed(request_whoi)(dataset_id) for dataset_id in whoi_gliders\n",
    ")\n",
    "\n",
    "dfs = {glider: df for (glider, df) in downloads}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally let's see some figures!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "from cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter\n",
    "\n",
    "\n",
    "def make_map():\n",
    "    fig, ax = plt.subplots(\n",
    "        figsize=(9, 9),\n",
    "        subplot_kw=dict(projection=ccrs.PlateCarree())\n",
    "    )\n",
    "    ax.coastlines(resolution=\"10m\")\n",
    "    lon_formatter = LongitudeFormatter(zero_direction_label=True)\n",
    "    lat_formatter = LatitudeFormatter()\n",
    "    ax.xaxis.set_major_formatter(lon_formatter)\n",
    "    ax.yaxis.set_major_formatter(lat_formatter)\n",
    "\n",
    "    return fig, ax\n",
    "\n",
    "\n",
    "fig, ax = make_map()\n",
    "lons, lats = [], []\n",
    "for glider, df in dfs.items():\n",
    "    lon, lat = df[\"longitude\"], df[\"latitude\"]\n",
    "    lons.extend(lon.array)\n",
    "    lats.extend(lat.array)\n",
    "    ax.plot(lon, lat)\n",
    "\n",
    "dx = dy = 0.25\n",
    "extent = min(lons)-dx, max(lons)+dx, min(lats)+dy, max(lats)+dy\n",
    "ax.set_extent(extent)\n",
    "\n",
    "ax.set_xticks([extent[0], extent[1]], crs=ccrs.PlateCarree())\n",
    "ax.set_yticks([extent[2], extent[3]], crs=ccrs.PlateCarree());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def glider_scatter(df, ax):\n",
    "    ax.scatter(df[\"temperature\"], df[\"salinity\"],\n",
    "               s=10, alpha=0.25)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(9, 9))\n",
    "ax.set_ylabel(\"salinity\")\n",
    "ax.set_xlabel(\"temperature\")\n",
    "ax.grid(True)\n",
    "\n",
    "for glider, df in dfs.items():\n",
    "    glider_scatter(df, ax)\n",
    "\n",
    "ax.axis([5.5, 30, 30, 38]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra convenience methods for common responses\n",
    "\n",
    "### OPeNDAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from netCDF4 import Dataset\n",
    "\n",
    "\n",
    "e.constraints = None\n",
    "e.protocol = \"tabledap\"\n",
    "e.dataset_id = \"whoi_406-20160902T1700\"\n",
    "\n",
    "opendap_url = e.get_download_url(\n",
    "    response=\"opendap\",\n",
    ")\n",
    "\n",
    "print(opendap_url)\n",
    "with Dataset(opendap_url) as nc:\n",
    "    print(nc.summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### netCDF Climate and Forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "e.response = \"nc\"\n",
    "e.variables = [\"longitude\", \"latitude\", \"temperature\", \"salinity\"]\n",
    "\n",
    "nc = e.to_ncCF()\n",
    "\n",
    "print(nc.Conventions)\n",
    "print(nc[\"temperature\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### xarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = e.to_xarray(decode_times=False)\n",
    "\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tabledap represents all data in tabular form and the next steps, while a bit awkward, are necessary to match the dimensions properly. The griddap response (unsupported at the moment) does not have this limitation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_size = ds[\"rowSize\"].values\n",
    "lon = ds[\"longitude\"].values\n",
    "lat = ds[\"latitude\"].values\n",
    "\n",
    "lons, lats = [], []\n",
    "for x, y, r in zip(lon, lat, row_size):\n",
    "    lons.extend([x]*r)\n",
    "    lats.extend([y]*r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "data = ds[\"temperature\"].values\n",
    "depth = ds[\"depth\"].values\n",
    "\n",
    "mask = ~np.ma.masked_invalid(depth).mask\n",
    "\n",
    "data = data[mask]\n",
    "depth = depth[mask]\n",
    "lons = np.array(lons)[mask]\n",
    "lats = np.array(lats)[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = depth <= 5\n",
    "\n",
    "data = data[mask]\n",
    "depth = depth[mask]\n",
    "lons = lons[mask]\n",
    "lats = lats[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "\n",
    "\n",
    "dx = dy = 1.5\n",
    "extent = (\n",
    "    ds.geospatial_lon_min-dx, ds.geospatial_lon_max+dx,\n",
    "    ds.geospatial_lat_min-dy, ds.geospatial_lat_max+dy\n",
    ")\n",
    "fig, ax = make_map()\n",
    "\n",
    "cs = ax.scatter(lons, lats, c=data, s=50, alpha=0.5, edgecolor=\"none\")\n",
    "cbar = fig.colorbar(cs, orientation=\"vertical\",\n",
    "                    fraction=0.1, shrink=0.9, extend=\"both\")\n",
    "ax.set_extent(extent)\n",
    "ax.coastlines(\"10m\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "# Iris warnings are quire verbose!\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    cubes = e.to_iris()\n",
    "\n",
    "print(cubes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cubes.extract_strict(\"sea_water_temperature\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example is written in a Jupyter Notebook\n",
    "[click here](https://raw.githubusercontent.com/ioos/erddapy/master/notebooks/quick_intro.ipynb)\n",
    "to download the notebook so you can run it locally, or [click here](https://binder.pangeo.io/v2/gh/ioos/erddapy/master?filepath=notebooks/quick_intro.ipynb) to run a live instance of this notebook."
   ]
  }
 ],
 "metadata": {
  "_draft": {
   "nbviewer_url": "https://gist.github.com/7e5eab16282538d11fdab7de5bd0c474"
  },
  "gist": {
   "data": {
    "description": "ERDDAP_advanced_glider_search.ipynb",
    "public": true
   },
   "id": "7e5eab16282538d11fdab7de5bd0c474"
  },
  "gist_id": "3f0f25b13ade0c64c84607bd92903d1b",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

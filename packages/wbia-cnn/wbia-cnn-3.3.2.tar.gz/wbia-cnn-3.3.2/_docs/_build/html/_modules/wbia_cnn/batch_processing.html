
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>wbia_cnn.batch_processing &#8212; wbia-cnn 3.3.0 documentation</title>
    <link rel="stylesheet" href="../../_static/alabaster.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
    <script id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/language_data.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
   
  <link rel="stylesheet" href="../../_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <h1>Source code for wbia_cnn.batch_processing</h1><div class="highlight"><pre>
<span></span><span class="c1"># -*- coding: utf-8 -*-</span>
<span class="kn">from</span> <span class="nn">__future__</span> <span class="kn">import</span> <span class="n">absolute_import</span><span class="p">,</span> <span class="n">division</span><span class="p">,</span> <span class="n">print_function</span>
<span class="kn">from</span> <span class="nn">wbia_cnn</span> <span class="kn">import</span> <span class="n">utils</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">six</span>
<span class="kn">import</span> <span class="nn">utool</span> <span class="k">as</span> <span class="nn">ut</span>

<span class="c1"># import warnings</span>
<span class="nb">print</span><span class="p">,</span> <span class="n">rrr</span><span class="p">,</span> <span class="n">profile</span> <span class="o">=</span> <span class="n">ut</span><span class="o">.</span><span class="n">inject2</span><span class="p">(</span><span class="vm">__name__</span><span class="p">)</span>


<span class="n">VERBOSE_BATCH</span> <span class="o">=</span> <span class="n">ut</span><span class="o">.</span><span class="n">get_module_verbosity_flags</span><span class="p">(</span><span class="s1">&#39;batch&#39;</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span> <span class="ow">or</span> <span class="n">utils</span><span class="o">.</span><span class="n">VERBOSE_CNN</span>
<span class="k">if</span> <span class="n">ut</span><span class="o">.</span><span class="n">VERYVERBOSE</span><span class="p">:</span>
    <span class="n">VERBOSE_BATCH</span> <span class="o">=</span> <span class="mi">2</span>

<span class="n">DEBUG_AUGMENTATION</span> <span class="o">=</span> <span class="n">ut</span><span class="o">.</span><span class="n">get_argflag</span><span class="p">(</span><span class="s1">&#39;--DEBUG_AUGMENTATION&#39;</span><span class="p">)</span>


<div class="viewcode-block" id="process_batch"><a class="viewcode-back" href="../../wbia_cnn.html#wbia_cnn.batch_processing.process_batch">[docs]</a><span class="nd">@profile</span>
<span class="k">def</span> <span class="nf">process_batch</span><span class="p">(</span>
    <span class="n">model</span><span class="p">,</span>
    <span class="n">X</span><span class="p">,</span>
    <span class="n">y</span><span class="p">,</span>
    <span class="n">theano_fn</span><span class="p">,</span>
    <span class="n">fix_output</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">buffered</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">show</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">spatial</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">showprog</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span>
<span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Compute the loss over all training batches.</span>
<span class="sd">    Passes data to function that splits it into batches and appropriately</span>
<span class="sd">    preproecsses the data. Then this function sends that data to theano. Then</span>
<span class="sd">    the results are packaged up nicely before returning.</span>

<span class="sd">    CommandLine:</span>
<span class="sd">        python -m wbia_cnn --tf process_batch --verbose</span>
<span class="sd">        python -m wbia_cnn --tf process_batch:0 --verbose</span>
<span class="sd">        python -m wbia_cnn --tf process_batch:1 --verbose</span>

<span class="sd">    Example0:</span>
<span class="sd">        &gt;&gt;&gt; # ENABLE_DOCTEST</span>
<span class="sd">        &gt;&gt;&gt; from wbia_cnn.batch_processing import *  # NOQA</span>
<span class="sd">        &gt;&gt;&gt; from wbia_cnn import models</span>
<span class="sd">        &gt;&gt;&gt; model = models.DummyModel(batch_size=128)</span>
<span class="sd">        &gt;&gt;&gt; X, y = model.make_random_testdata(num=2000, seed=None)</span>
<span class="sd">        &gt;&gt;&gt; model.init_arch()</span>
<span class="sd">        &gt;&gt;&gt; theano_fn = model.build_predict_func()</span>
<span class="sd">        &gt;&gt;&gt; kwargs = {&#39;X_is_cv2_native&#39;: False, &#39;showprog&#39;: True,</span>
<span class="sd">        ...           &#39;randomize_batch_order&#39;: True}</span>
<span class="sd">        &gt;&gt;&gt; outputs_ = process_batch(model, X, y, theano_fn, **kwargs)</span>
<span class="sd">        &gt;&gt;&gt; result = ut.dict_str(outputs_)</span>
<span class="sd">        &gt;&gt;&gt; print(result)</span>

<span class="sd">    Example0:</span>
<span class="sd">        &gt;&gt;&gt; # ENABLE_DOCTEST</span>
<span class="sd">        &gt;&gt;&gt; from wbia_cnn.batch_processing import *  # NOQA</span>
<span class="sd">        &gt;&gt;&gt; from wbia_cnn import models</span>
<span class="sd">        &gt;&gt;&gt; model = models.SiameseL2(batch_size=128, data_shape=(32, 32, 1),</span>
<span class="sd">        ...                          strict_batch_size=True)</span>
<span class="sd">        &gt;&gt;&gt; X, y = model.make_random_testdata(num=2000, seed=None)</span>
<span class="sd">        &gt;&gt;&gt; model.init_arch()</span>
<span class="sd">        &gt;&gt;&gt; theano_fn = model.build_predict_func()</span>
<span class="sd">        &gt;&gt;&gt; kwargs = {&#39;X_is_cv2_native&#39;: False, &#39;showprog&#39;: True,</span>
<span class="sd">        ...           &#39;randomize_batch_order&#39;: True}</span>
<span class="sd">        &gt;&gt;&gt; outputs_ = process_batch(model, X, y, theano_fn, **kwargs)</span>
<span class="sd">        &gt;&gt;&gt; result = ut.dict_str(outputs_)</span>
<span class="sd">        &gt;&gt;&gt; print(result)</span>

<span class="sd">    Ignore:</span>
<span class="sd">        Xb, yb = batch_iter.next()</span>
<span class="sd">        assert Xb.shape == (8, 1, 4, 4)</span>
<span class="sd">        yb.shape == (8,)</span>

<span class="sd">    Ignore:</span>
<span class="sd">        X, y = model.make_random_testdata(num=2000, seed=None)</span>
<span class="sd">        kwargs = {&#39;X_is_cv2_native&#39;: False, &#39;showprog&#39;: True,</span>
<span class="sd">                  &#39;randomize_batch_order&#39;: True, &#39;time_thresh&#39;: .5,</span>
<span class="sd">                  }</span>

<span class="sd">        print(&#39;Testing Unbuffered&#39;)</span>
<span class="sd">        batch_iter = batch_iterator(model, X, y, lbl=theano_fn.name, **kwargs)</span>
<span class="sd">        for Xb, yb in ut.ProgressIter(batch_iter, lbl=&#39;:EXEC FG&#39;):</span>
<span class="sd">            [ut.is_prime(346373) for _ in range(2)]</span>

<span class="sd">        # Notice how the progress iters are not interlaced like</span>
<span class="sd">        # they are in the unbuffered version</span>
<span class="sd">        import sys</span>
<span class="sd">        sys.stdout.flush()</span>
<span class="sd">        print(&#39;Testing Buffered&#39;)</span>
<span class="sd">        sys.stdout.flush()</span>
<span class="sd">        batch_iter2 = batch_iterator(model, X, y, lbl=theano_fn.name, **kwargs)</span>
<span class="sd">        batch_iter2 = ut.buffered_generator(batch_iter2, buffer_size=4)</span>
<span class="sd">        print(&#39;Iterating&#39;)</span>
<span class="sd">        for Xb, yb in ut.ProgressIter(batch_iter2, lbl=&#39;:EXEC FG&#39;):</span>
<span class="sd">            [ut.is_prime(346373) for _ in range(2)]</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="kn">import</span> <span class="nn">vtool</span> <span class="k">as</span> <span class="nn">vt</span>

    <span class="n">batch_output_list</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">output_names</span> <span class="o">=</span> <span class="p">[</span>
        <span class="nb">str</span><span class="p">(</span><span class="n">outexpr</span><span class="o">.</span><span class="n">variable</span><span class="p">)</span> <span class="k">if</span> <span class="n">outexpr</span><span class="o">.</span><span class="n">variable</span><span class="o">.</span><span class="n">name</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">outexpr</span><span class="o">.</span><span class="n">variable</span><span class="o">.</span><span class="n">name</span>
        <span class="k">for</span> <span class="n">outexpr</span> <span class="ow">in</span> <span class="n">theano_fn</span><span class="o">.</span><span class="n">outputs</span>
    <span class="p">]</span>
    <span class="c1"># augmented label list</span>
    <span class="n">batch_target_list</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">show</span> <span class="o">=</span> <span class="n">VERBOSE_BATCH</span> <span class="ow">or</span> <span class="n">show</span>

    <span class="c1"># Break data into generated batches</span>
    <span class="c1"># generated data with explicit iteration</span>
    <span class="n">batch_iter</span> <span class="o">=</span> <span class="n">batch_iterator</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">buffered</span><span class="p">:</span>
        <span class="n">batch_iter</span> <span class="o">=</span> <span class="n">ut</span><span class="o">.</span><span class="n">buffered_generator</span><span class="p">(</span><span class="n">batch_iter</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">showprog</span><span class="p">:</span>
        <span class="n">bs</span> <span class="o">=</span> <span class="n">VERBOSE_BATCH</span> <span class="o">&lt;</span> <span class="mi">1</span>
        <span class="n">num_batches</span> <span class="o">=</span> <span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="n">model</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">//</span> <span class="n">model</span><span class="o">.</span><span class="n">batch_size</span>
        <span class="c1"># progress iterator should be outside of this function</span>
        <span class="n">batch_iter</span> <span class="o">=</span> <span class="n">ut</span><span class="o">.</span><span class="n">ProgressIter</span><span class="p">(</span>
            <span class="n">batch_iter</span><span class="p">,</span>
            <span class="n">nTotal</span><span class="o">=</span><span class="n">num_batches</span><span class="p">,</span>
            <span class="n">lbl</span><span class="o">=</span><span class="n">theano_fn</span><span class="o">.</span><span class="n">name</span><span class="p">,</span>
            <span class="n">freq</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
            <span class="n">bs</span><span class="o">=</span><span class="n">bs</span><span class="p">,</span>
            <span class="n">adjust</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="p">)</span>
    <span class="k">if</span> <span class="n">y</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="c1"># Labels are not known, only one argument</span>
        <span class="k">for</span> <span class="n">Xb</span><span class="p">,</span> <span class="n">yb</span> <span class="ow">in</span> <span class="n">batch_iter</span><span class="p">:</span>
            <span class="k">pass</span>
            <span class="n">batch_output</span> <span class="o">=</span> <span class="n">theano_fn</span><span class="p">(</span><span class="n">Xb</span><span class="p">)</span>
            <span class="n">batch_output_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">batch_output</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="c1"># TODO: sliced batches</span>
        <span class="k">for</span> <span class="n">Xb</span><span class="p">,</span> <span class="n">yb</span> <span class="ow">in</span> <span class="n">batch_iter</span><span class="p">:</span>
            <span class="c1"># Runs a batch through the network and updates the weights. Just</span>
            <span class="c1"># returns what it did</span>
            <span class="n">batch_output</span> <span class="o">=</span> <span class="n">theano_fn</span><span class="p">(</span><span class="n">Xb</span><span class="p">,</span> <span class="n">yb</span><span class="p">)</span>
            <span class="n">batch_output_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">batch_output</span><span class="p">)</span>
            <span class="n">batch_target_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">yb</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">show</span><span class="p">:</span>
                <span class="c1"># Print the network output for the first batch</span>
                <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;--------------&#39;</span><span class="p">)</span>
                <span class="nb">print</span><span class="p">(</span><span class="n">ut</span><span class="o">.</span><span class="n">list_str</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">output_names</span><span class="p">,</span> <span class="n">batch_output</span><span class="p">)))</span>
                <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Correct: &#39;</span><span class="p">,</span> <span class="n">yb</span><span class="p">)</span>
                <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;--------------&#39;</span><span class="p">)</span>
                <span class="n">show</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="c1"># get outputs of each type</span>
    <span class="n">unstacked_output_gen</span> <span class="o">=</span> <span class="p">(</span>
        <span class="p">[</span><span class="n">bop</span><span class="p">[</span><span class="n">count</span><span class="p">]</span> <span class="k">for</span> <span class="n">bop</span> <span class="ow">in</span> <span class="n">batch_output_list</span><span class="p">]</span>
        <span class="k">for</span> <span class="n">count</span><span class="p">,</span> <span class="n">name</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">output_names</span><span class="p">)</span>
    <span class="p">)</span>

    <span class="k">if</span> <span class="n">spatial</span><span class="p">:</span>
        <span class="n">unstacked_output_gen</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">unstacked_output_gen</span><span class="p">)</span>
        <span class="n">stacked_output_list</span> <span class="o">=</span> <span class="p">[[]</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">unstacked_output_gen</span><span class="p">))]</span>
        <span class="k">for</span> <span class="n">index</span><span class="p">,</span> <span class="n">output</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">unstacked_output_gen</span><span class="p">):</span>
            <span class="n">output</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
            <span class="n">stacked_output_list</span><span class="p">[</span><span class="n">index</span><span class="p">]</span> <span class="o">=</span> <span class="n">output</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">stacked_output_list</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">vt</span><span class="o">.</span><span class="n">safe_cat</span><span class="p">(</span><span class="n">_output_unstacked</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
            <span class="c1"># concatenate_hack(_output_unstacked, axis=0)</span>
            <span class="k">for</span> <span class="n">_output_unstacked</span> <span class="ow">in</span> <span class="n">unstacked_output_gen</span>
        <span class="p">]</span>

    <span class="n">outputs_</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">output_names</span><span class="p">,</span> <span class="n">stacked_output_list</span><span class="p">))</span>

    <span class="k">if</span> <span class="n">y</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">auglbl_list</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">(</span><span class="n">batch_target_list</span><span class="p">)</span>
        <span class="n">outputs_</span><span class="p">[</span><span class="s1">&#39;auglbl_list&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">auglbl_list</span>

    <span class="k">if</span> <span class="n">fix_output</span><span class="p">:</span>
        <span class="c1"># batch iteration may wrap-around returned data. slice off the padding</span>
        <span class="n">num_inputs</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">/</span> <span class="n">model</span><span class="o">.</span><span class="n">data_per_label_input</span>
        <span class="n">num_outputs</span> <span class="o">=</span> <span class="n">num_inputs</span> <span class="o">*</span> <span class="n">model</span><span class="o">.</span><span class="n">data_per_label_output</span>
        <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">six</span><span class="o">.</span><span class="n">iterkeys</span><span class="p">(</span><span class="n">outputs_</span><span class="p">):</span>
            <span class="n">outputs_</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">outputs_</span><span class="p">[</span><span class="n">key</span><span class="p">][</span><span class="mi">0</span><span class="p">:</span><span class="n">num_outputs</span><span class="p">]</span>

    <span class="n">encoder</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;encoder&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">encoder</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="s1">&#39;predictions&#39;</span> <span class="ow">in</span> <span class="n">outputs_</span><span class="p">:</span>
        <span class="n">pred</span> <span class="o">=</span> <span class="n">outputs_</span><span class="p">[</span><span class="s1">&#39;predictions&#39;</span><span class="p">]</span>
        <span class="n">outputs_</span><span class="p">[</span><span class="s1">&#39;labeled_predictions&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">encoder</span><span class="o">.</span><span class="n">inverse_transform</span><span class="p">(</span><span class="n">pred</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">outputs_</span></div>


<div class="viewcode-block" id="batch_iterator"><a class="viewcode-back" href="../../wbia_cnn.html#wbia_cnn.batch_processing.batch_iterator">[docs]</a><span class="nd">@profile</span>
<span class="k">def</span> <span class="nf">batch_iterator</span><span class="p">(</span>
    <span class="n">model</span><span class="p">,</span>
    <span class="n">X</span><span class="p">,</span>
    <span class="n">y</span><span class="p">,</span>
    <span class="n">randomize_batch_order</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">augment_on</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">X_is_cv2_native</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">verbose</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">lbl</span><span class="o">=</span><span class="s1">&#39;verbose batch iteration&#39;</span><span class="p">,</span>
<span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Breaks up data into to batches defined by model batch size</span>

<span class="sd">    CommandLine:</span>
<span class="sd">        python -m wbia_cnn --tf batch_iterator:0</span>
<span class="sd">        python -m wbia_cnn --tf batch_iterator:1</span>
<span class="sd">        python -m wbia_cnn --tf batch_iterator:2</span>
<span class="sd">        python -m wbia_cnn --tf batch_iterator:1 --DEBUG_AUGMENTATION</span>

<span class="sd">        python -m wbia_cnn --tf batch_iterator:1 --noaugment</span>
<span class="sd">        # Threaded buffering seems to help a lot</span>
<span class="sd">        python -m wbia_cnn --tf batch_iterator:1 --augment</span>

<span class="sd">    Example0:</span>
<span class="sd">        &gt;&gt;&gt; # ENABLE_DOCTEST</span>
<span class="sd">        &gt;&gt;&gt; from wbia_cnn.batch_processing import *  # NOQA</span>
<span class="sd">        &gt;&gt;&gt; from wbia_cnn import models</span>
<span class="sd">        &gt;&gt;&gt; model = models.DummyModel(batch_size=16)</span>
<span class="sd">        &gt;&gt;&gt; X, y = model.make_random_testdata(num=99, seed=None, cv2_format=True)</span>
<span class="sd">        &gt;&gt;&gt; model.ensure_data_params(X, y)</span>
<span class="sd">        &gt;&gt;&gt; y = None</span>
<span class="sd">        &gt;&gt;&gt; encoder = None</span>
<span class="sd">        &gt;&gt;&gt; randomize_batch_order = True</span>
<span class="sd">        &gt;&gt;&gt; result_list = [(Xb, Yb) for Xb, Yb in batch_iterator(model, X, y,</span>
<span class="sd">        ...                randomize_batch_order)]</span>
<span class="sd">        &gt;&gt;&gt; result = ut.depth_profile(result_list, compress_consecutive=True)</span>
<span class="sd">        &gt;&gt;&gt; print(result)</span>
<span class="sd">        [[(16, 1, 4, 4), 16]] * 6 + [[(3, 1, 4, 4), 3]]</span>

<span class="sd">    Example1:</span>
<span class="sd">        &gt;&gt;&gt; # ENABLE_DOCTEST</span>
<span class="sd">        &gt;&gt;&gt; from wbia_cnn.batch_processing import *  # NOQA</span>
<span class="sd">        &gt;&gt;&gt; from wbia_cnn import models</span>
<span class="sd">        &gt;&gt;&gt; import time</span>
<span class="sd">        &gt;&gt;&gt; model = models.SiameseL2(batch_size=128, data_shape=(8, 8, 1))</span>
<span class="sd">        &gt;&gt;&gt; X, y = model.make_random_testdata(num=1000, seed=None, cv2_format=True)</span>
<span class="sd">        &gt;&gt;&gt; model.ensure_data_params(X, y)</span>
<span class="sd">        &gt;&gt;&gt; encoder = None</span>
<span class="sd">        &gt;&gt;&gt; result_list1 = []</span>
<span class="sd">        &gt;&gt;&gt; result_list2 = []</span>
<span class="sd">        &gt;&gt;&gt; augment_on=not ut.get_argflag(&#39;--noaugment&#39;)</span>
<span class="sd">        &gt;&gt;&gt; iterkw = dict(randomize_batch_order=True,</span>
<span class="sd">        &gt;&gt;&gt;              augment_on=augment_on,</span>
<span class="sd">        &gt;&gt;&gt;              showprog=True, verbose=ut.VERBOSE)</span>
<span class="sd">        &gt;&gt;&gt; sleep_time = .05</span>
<span class="sd">        &gt;&gt;&gt; inside_time1 = 0</span>
<span class="sd">        &gt;&gt;&gt; inside_time2 = 0</span>
<span class="sd">        &gt;&gt;&gt; with ut.Timer(&#39;buffered&#39;) as t2:</span>
<span class="sd">        &gt;&gt;&gt;     generator =  batch_iterator(model, X, y, **iterkw)</span>
<span class="sd">        &gt;&gt;&gt;     for Xb, Yb in ut.buffered_generator(generator, buffer_size=3):</span>
<span class="sd">        &gt;&gt;&gt;         with ut.Timer(&#39;Inside&#39;, verbose=False) as t:</span>
<span class="sd">        &gt;&gt;&gt;             time.sleep(sleep_time)</span>
<span class="sd">        &gt;&gt;&gt;             result_list2.append(Xb.shape)</span>
<span class="sd">        &gt;&gt;&gt;         inside_time2 += t.ellapsed</span>
<span class="sd">        &gt;&gt;&gt; with ut.Timer(&#39;unbuffered&#39;) as t1:</span>
<span class="sd">        &gt;&gt;&gt;     generator =  batch_iterator(model, X, y, **iterkw)</span>
<span class="sd">        &gt;&gt;&gt;     for Xb, Yb in generator:</span>
<span class="sd">        &gt;&gt;&gt;         with ut.Timer(&#39;Inside&#39;, verbose=False) as t:</span>
<span class="sd">        &gt;&gt;&gt;             time.sleep(sleep_time)</span>
<span class="sd">        &gt;&gt;&gt;             result_list1.append(Xb.shape)</span>
<span class="sd">        &gt;&gt;&gt;         inside_time1 += t.ellapsed</span>
<span class="sd">        &gt;&gt;&gt; print(&#39;\nInside times should be the same&#39;)</span>
<span class="sd">        &gt;&gt;&gt; print(&#39;inside_time1 = %r&#39; % (inside_time1,))</span>
<span class="sd">        &gt;&gt;&gt; print(&#39;inside_time2 = %r&#39; % (inside_time2,))</span>
<span class="sd">        &gt;&gt;&gt; print(&#39;Outside times show the overhead of data augmentation&#39;)</span>
<span class="sd">        &gt;&gt;&gt; print(&#39;Overhead Unbuffered = %r&#39; % (t1.ellapsed - inside_time1,))</span>
<span class="sd">        &gt;&gt;&gt; print(&#39;Overhead Buffered   = %r&#39; % (t2.ellapsed - inside_time2,))</span>
<span class="sd">        &gt;&gt;&gt; print(&#39;Efficiency Unbuffered  = %.2f&#39; % (100 * inside_time1 / t1.ellapsed,))</span>
<span class="sd">        &gt;&gt;&gt; print(&#39;Efficiency Buffered    = %.2f&#39; % (100 * inside_time2 / t2.ellapsed,))</span>
<span class="sd">        &gt;&gt;&gt; assert result_list1 == result_list2</span>
<span class="sd">        &gt;&gt;&gt; print(len(result_list2))</span>

<span class="sd">    Example2:</span>
<span class="sd">        &gt;&gt;&gt; # DISABLE_DOCTEST</span>
<span class="sd">        &gt;&gt;&gt; from wbia_cnn.batch_processing import *  # NOQA</span>
<span class="sd">        &gt;&gt;&gt; from wbia_cnn.models.mnist import MNISTModel</span>
<span class="sd">        &gt;&gt;&gt; from wbia_cnn import ingest_data</span>
<span class="sd">        &gt;&gt;&gt; # should yield float32 regardlesss of original format</span>
<span class="sd">        &gt;&gt;&gt; ut.exec_funckw(batch_iterator, globals())</span>
<span class="sd">        &gt;&gt;&gt; randomize_batch_order = False</span>
<span class="sd">        &gt;&gt;&gt; # ---</span>
<span class="sd">        &gt;&gt;&gt; dataset1 = ingest_data.grab_mnist_category_dataset_float()</span>
<span class="sd">        &gt;&gt;&gt; model1 = MNISTModel(batch_size=8, data_shape=dataset1.data_shape,</span>
<span class="sd">        &gt;&gt;&gt;                    output_dims=dataset1.output_dims,</span>
<span class="sd">        &gt;&gt;&gt;                    arch_tag=dataset1.alias_key,</span>
<span class="sd">        &gt;&gt;&gt;                    training_dpath=dataset1.training_dpath)</span>
<span class="sd">        &gt;&gt;&gt; X1, y1 = dataset1.subset(&#39;train&#39;)</span>
<span class="sd">        &gt;&gt;&gt; model1.ensure_data_params(X1, y1)</span>
<span class="sd">        &gt;&gt;&gt; _iter1 = batch_iterator(model1, X1, y1, randomize_batch_order)</span>
<span class="sd">        &gt;&gt;&gt; Xb1, yb1 = six.next(_iter1)</span>
<span class="sd">        &gt;&gt;&gt; # ---</span>
<span class="sd">        &gt;&gt;&gt; dataset2 = ingest_data.grab_mnist_category_dataset()</span>
<span class="sd">        &gt;&gt;&gt; model2 = MNISTModel(batch_size=8, data_shape=dataset2.data_shape,</span>
<span class="sd">        &gt;&gt;&gt;                    output_dims=dataset2.output_dims,</span>
<span class="sd">        &gt;&gt;&gt;                    arch_tag=dataset2.alias_key,</span>
<span class="sd">        &gt;&gt;&gt;                    training_dpath=dataset2.training_dpath)</span>
<span class="sd">        &gt;&gt;&gt; X2, y2 = dataset2.subset(&#39;train&#39;)</span>
<span class="sd">        &gt;&gt;&gt; model2.ensure_data_params(X2, y2)</span>
<span class="sd">        &gt;&gt;&gt; _iter2 = batch_iterator(model2, X2, y2, randomize_batch_order)</span>
<span class="sd">        &gt;&gt;&gt; Xb2, yb2 = six.next(_iter2)</span>
<span class="sd">        &gt;&gt;&gt; # ---</span>
<span class="sd">        &gt;&gt;&gt; X, y, model = X1, y1, model1</span>
<span class="sd">        &gt;&gt;&gt; assert np.all(yb2 == yb2)</span>
<span class="sd">        &gt;&gt;&gt; # The uint8 and float32 data should produce similar values</span>
<span class="sd">        &gt;&gt;&gt; # For this mnist set it will be a bit more off because the</span>
<span class="sd">        &gt;&gt;&gt; # original uint8 scaling value was 256 not 255.</span>
<span class="sd">        &gt;&gt;&gt; assert (Xb1[0] - Xb2[0]).max() &lt; .1</span>
<span class="sd">        &gt;&gt;&gt; assert np.isclose(Xb1.mean(), 0, atol=.01)</span>
<span class="sd">        &gt;&gt;&gt; assert np.isclose(Xb2.mean(), 0, atol=.01)</span>
<span class="sd">        &gt;&gt;&gt; assert Xb1.max() &lt;  1.0 and Xb2.max() &lt;  1.0, &#39;out of (-1, 1)&#39;</span>
<span class="sd">        &gt;&gt;&gt; assert Xb1.min() &gt; -1.0 and Xb1.min() &gt; -1.0, &#39;out of (-1, 1)&#39;</span>
<span class="sd">        &gt;&gt;&gt; assert Xb1.min() &lt; 0, &#39;should have some negative values&#39;</span>
<span class="sd">        &gt;&gt;&gt; assert Xb2.min() &lt; 0, &#39;should have some negative values&#39;</span>
<span class="sd">        &gt;&gt;&gt; assert Xb1.max() &gt; 0, &#39;should have some positive values&#39;</span>
<span class="sd">        &gt;&gt;&gt; assert Xb2.max() &gt; 0, &#39;should have some positive values&#39;</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
        <span class="n">verbose</span> <span class="o">=</span> <span class="n">VERBOSE_BATCH</span>

    <span class="c1"># need to be careful with batchsizes if directly specified to theano</span>
    <span class="n">wraparound</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">input_shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
    <span class="n">augment_on</span> <span class="o">=</span> <span class="n">augment_on</span> <span class="ow">and</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;augment&#39;</span><span class="p">)</span>
    <span class="n">encoder</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;encoder&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
    <span class="n">needs_convert</span> <span class="o">=</span> <span class="n">ut</span><span class="o">.</span><span class="n">is_int</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">y</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">assert</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="p">(</span>
            <span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">model</span><span class="o">.</span><span class="n">data_per_label_input</span>
        <span class="p">),</span> <span class="s1">&#39;bad data / label alignment&#39;</span>
    <span class="n">num_batches</span> <span class="o">=</span> <span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="n">model</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">//</span> <span class="n">model</span><span class="o">.</span><span class="n">batch_size</span>

    <span class="k">if</span> <span class="n">randomize_batch_order</span><span class="p">:</span>
        <span class="c1"># Randomly shuffle data</span>
        <span class="c1"># 0.079 mnist time fraction</span>
        <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">data_label_shuffle</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">data_per_label_input</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;[batchiter] BEGIN&#39;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;[batchiter] X.shape </span><span class="si">%r</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">,))</span>
        <span class="k">if</span> <span class="n">y</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;[batchiter] y.shape </span><span class="si">%r</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">,))</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;[batchiter] augment_on </span><span class="si">%r</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">augment_on</span><span class="p">,))</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;[batchiter] encoder </span><span class="si">%r</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">encoder</span><span class="p">,))</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;[batchiter] wraparound </span><span class="si">%r</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">wraparound</span><span class="p">,))</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;[batchiter] model.data_per_label_input </span><span class="si">%r</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">data_per_label_input</span><span class="p">,))</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;[batchiter] needs_convert = </span><span class="si">%r</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">needs_convert</span><span class="p">,))</span>

    <span class="c1"># FIXME: put in a layer?</span>
    <span class="n">center_mean</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">center_std</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="c1"># Load precomputed whitening parameters</span>
    <span class="k">if</span> <span class="n">model</span><span class="o">.</span><span class="n">data_params</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">center_mean</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">data_params</span><span class="p">[</span><span class="s1">&#39;center_mean&#39;</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
        <span class="n">center_std</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">data_params</span><span class="p">[</span><span class="s1">&#39;center_std&#39;</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">do_whitening</span> <span class="o">=</span> <span class="p">(</span>
        <span class="n">center_mean</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">center_std</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">center_std</span> <span class="o">!=</span> <span class="mf">0.0</span>
    <span class="p">)</span>

    <span class="k">if</span> <span class="n">needs_convert</span><span class="p">:</span>
        <span class="n">ceneter_mean01</span> <span class="o">=</span> <span class="n">center_mean</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="mf">255.0</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
        <span class="n">center_std01</span> <span class="o">=</span> <span class="n">center_std</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="mf">255.0</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">ceneter_mean01</span> <span class="o">=</span> <span class="n">center_mean</span>
        <span class="n">center_std01</span> <span class="o">=</span> <span class="n">center_std</span>

    <span class="c1"># Slice and preprocess data in batch</span>
    <span class="k">for</span> <span class="n">batch_index</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_batches</span><span class="p">):</span>
        <span class="c1"># Take a slice from the data</span>
        <span class="n">Xb_orig</span><span class="p">,</span> <span class="n">yb_orig</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">slice_data_labels</span><span class="p">(</span>
            <span class="n">X</span><span class="p">,</span>
            <span class="n">y</span><span class="p">,</span>
            <span class="n">model</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span>
            <span class="n">batch_index</span><span class="p">,</span>
            <span class="n">model</span><span class="o">.</span><span class="n">data_per_label_input</span><span class="p">,</span>
            <span class="n">wraparound</span><span class="o">=</span><span class="n">wraparound</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="c1"># Ensure correct format for the GPU</span>
        <span class="n">Xb</span> <span class="o">=</span> <span class="n">Xb_orig</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
        <span class="n">yb</span> <span class="o">=</span> <span class="kc">None</span> <span class="k">if</span> <span class="n">yb_orig</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">yb_orig</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">needs_convert</span><span class="p">:</span>
            <span class="c1"># Rescale the batch data to the range 0 to 1</span>
            <span class="n">Xb</span> <span class="o">=</span> <span class="n">Xb</span> <span class="o">/</span> <span class="mf">255.0</span>
        <span class="k">if</span> <span class="n">augment_on</span><span class="p">:</span>
            <span class="c1"># Apply defined transformations</span>
            <span class="p">(</span>
                <span class="n">Xb</span><span class="p">,</span>
                <span class="n">yb</span><span class="p">,</span>
            <span class="p">)</span> <span class="o">=</span> <span class="n">augment_batch</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">Xb</span><span class="p">,</span> <span class="n">yb</span><span class="p">,</span> <span class="n">batch_index</span><span class="p">,</span> <span class="n">verbose</span><span class="p">,</span> <span class="n">num_batches</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">do_whitening</span><span class="p">:</span>
            <span class="c1"># Center the batch data in the range (-1.0, 1.0)</span>
            <span class="n">Xb</span> <span class="o">=</span> <span class="p">(</span><span class="n">Xb</span> <span class="o">-</span> <span class="n">ceneter_mean01</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">center_std01</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">X_is_cv2_native</span><span class="p">:</span>
            <span class="c1"># Convert from cv2 to lasagne format</span>
            <span class="n">Xb</span> <span class="o">=</span> <span class="n">Xb</span><span class="o">.</span><span class="n">transpose</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
        <span class="k">if</span> <span class="n">yb</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">encoder</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="c1"># Apply an encoding if applicable</span>
                <span class="n">yb</span> <span class="o">=</span> <span class="n">encoder</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">yb</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">model</span><span class="o">.</span><span class="n">data_per_label_input</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="ow">and</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;needs_padding&#39;</span><span class="p">,</span> <span class="kc">False</span><span class="p">):</span>
                <span class="c1"># Pad data for siamese networks</span>
                <span class="n">yb</span> <span class="o">=</span> <span class="n">pad_labels</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">yb</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
            <span class="c1"># Print info if requested</span>
            <span class="n">print_batch_info</span><span class="p">(</span><span class="n">Xb</span><span class="p">,</span> <span class="n">yb</span><span class="p">,</span> <span class="n">verbose</span><span class="p">,</span> <span class="n">batch_index</span><span class="p">,</span> <span class="n">num_batches</span><span class="p">)</span>
        <span class="k">yield</span> <span class="n">Xb</span><span class="p">,</span> <span class="n">yb</span>
    <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;[batch] END&#39;</span><span class="p">)</span></div>


<div class="viewcode-block" id="augment_batch"><a class="viewcode-back" href="../../wbia_cnn.html#wbia_cnn.batch_processing.augment_batch">[docs]</a><span class="k">def</span> <span class="nf">augment_batch</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">Xb</span><span class="p">,</span> <span class="n">yb</span><span class="p">,</span> <span class="n">batch_index</span><span class="p">,</span> <span class="n">verbose</span><span class="p">,</span> <span class="n">num_batches</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Make sure to augment data in 0-1 space.</span>
<span class="sd">    This means use a mean fill values not 0.</span>

<span class="sd">    &gt;&gt;&gt; from wbia_cnn import augment</span>
<span class="sd">    &gt;&gt;&gt; import plottool as pt</span>
<span class="sd">    &gt;&gt;&gt; pt.qt4ensure()</span>
<span class="sd">    &gt;&gt;&gt; augment.show_augmented_patches(Xb_orig, Xb, yb_orig, yb)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">verbose</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="ow">or</span> <span class="p">(</span><span class="n">batch_index</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="n">num_batches</span> <span class="o">&lt;=</span> <span class="mi">1</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Augmenting Data&#39;</span><span class="p">)</span>
            <span class="c1"># only copy if we have&#39;t yet</span>
    <span class="n">Xb</span><span class="p">,</span> <span class="n">yb</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">augment</span><span class="p">(</span><span class="n">Xb</span><span class="p">,</span> <span class="n">yb</span><span class="p">)</span>
    <span class="c1"># if DEBUG_AUGMENTATION:</span>
    <span class="c1">#    #Xb, yb = augment.augment_siamese_patches2(Xb, yb)</span>
    <span class="c1">#    from wbia_cnn import augment</span>
    <span class="c1">#    import plottool as pt</span>
    <span class="c1">#    augment.show_augmented_patches(Xb_orig, Xb, yb_orig, yb)</span>
    <span class="c1">#    pt.show_if_requested()</span>
    <span class="c1">#    ut.embed()</span>
    <span class="k">return</span> <span class="n">Xb</span><span class="p">,</span> <span class="n">yb</span></div>


<div class="viewcode-block" id="pad_labels"><a class="viewcode-back" href="../../wbia_cnn.html#wbia_cnn.batch_processing.pad_labels">[docs]</a><span class="k">def</span> <span class="nf">pad_labels</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">yb</span><span class="p">):</span>
    <span class="c1"># TODO: FIX data_per_label_input ISSUES</span>
    <span class="c1"># most models will do the padding implicitly</span>
    <span class="c1"># in the layer architecture</span>
    <span class="n">pad_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">yb</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">data_per_label_input</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">yb_buffer</span> <span class="o">=</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">pad_size</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
    <span class="n">yb</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">((</span><span class="n">yb</span><span class="p">,</span> <span class="n">yb_buffer</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">yb</span></div>


<div class="viewcode-block" id="print_batch_info"><a class="viewcode-back" href="../../wbia_cnn.html#wbia_cnn.batch_processing.print_batch_info">[docs]</a><span class="k">def</span> <span class="nf">print_batch_info</span><span class="p">(</span><span class="n">Xb</span><span class="p">,</span> <span class="n">yb</span><span class="p">,</span> <span class="n">verbose</span><span class="p">,</span> <span class="n">batch_index</span><span class="p">,</span> <span class="n">num_batches</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">verbose</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="ow">or</span> <span class="p">(</span><span class="n">batch_index</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="n">num_batches</span> <span class="o">&lt;=</span> <span class="mi">1</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;[batch] Yielding batch: batch_index = </span><span class="si">%r</span><span class="s1"> &#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">batch_index</span><span class="p">,))</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;[batch]   * Xb.shape = </span><span class="si">%r</span><span class="s1">, Xb.dtype=</span><span class="si">%r</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">Xb</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">Xb</span><span class="o">.</span><span class="n">dtype</span><span class="p">))</span>
        <span class="k">if</span> <span class="n">yb</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;[batch]   * yb.shape = </span><span class="si">%r</span><span class="s1">, yb.dtype=</span><span class="si">%r</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">yb</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">yb</span><span class="o">.</span><span class="n">dtype</span><span class="p">))</span>
            <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;[batch]   * yb.sum = </span><span class="si">%r</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">yb</span><span class="o">.</span><span class="n">sum</span><span class="p">(),))</span></div>


<div class="viewcode-block" id="concatenate_hack"><a class="viewcode-back" href="../../wbia_cnn.html#wbia_cnn.batch_processing.concatenate_hack">[docs]</a><span class="k">def</span> <span class="nf">concatenate_hack</span><span class="p">(</span><span class="n">sequence</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Hack to fix numpy bug.</span>
<span class="sd">    concatenate fails when one item in sequence is empty</span>

<span class="sd">    &gt;&gt;&gt; sequence = (np.array([[]]), np.array([[1, 2, 3]]))</span>
<span class="sd">    &gt;&gt;&gt; sequence = (np.array([[1, 2, 3]]), np.array([[]]))</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># print(sequence)</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">sequence</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">sequence</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">arr</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">(</span><span class="n">sequence</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">arr</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">sequence</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="n">axis</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">arr</span></div>


<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s1">&#39;__main__&#39;</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    CommandLine:</span>
<span class="sd">        python -m wbia_cnn.batch_processing</span>
<span class="sd">        python -m wbia_cnn.batch_processing --allexamples</span>
<span class="sd">        python -m wbia_cnn.batch_processing --allexamples --noface --nosrc</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="kn">import</span> <span class="nn">multiprocessing</span>

    <span class="n">multiprocessing</span><span class="o">.</span><span class="n">freeze_support</span><span class="p">()</span>  <span class="c1"># for win32</span>
    <span class="kn">import</span> <span class="nn">utool</span> <span class="k">as</span> <span class="nn">ut</span>  <span class="c1"># NOQA</span>

    <span class="n">ut</span><span class="o">.</span><span class="n">doctest_funcs</span><span class="p">()</span>
</pre></div>

          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="../../index.html">wbia-cnn</a></h1>








<h3>Navigation</h3>
<p class="caption"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../wbia_cnn.html">wbia_cnn package</a></li>
</ul>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="../../index.html">Documentation overview</a><ul>
  <li><a href="../index.html">Module code</a><ul>
  <li><a href="../wbia_cnn.html">wbia_cnn</a><ul>
  </ul></li>
  </ul></li>
  </ul></li>
</ul>
</div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" />
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>$('#searchbox').show(0);</script>








        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2020, Wild Me.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 3.2.1</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.12</a>
      
    </div>

    

    
  </body>
</html>

<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>wbia_cnn.lasagne_ext &#8212; wbia-cnn 3.3.0 documentation</title>
    <link rel="stylesheet" href="../../_static/alabaster.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
    <script id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/language_data.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
   
  <link rel="stylesheet" href="../../_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <h1>Source code for wbia_cnn.lasagne_ext</h1><div class="highlight"><pre>
<span></span><span class="c1"># -*- coding: utf-8 -*-</span>
<span class="kn">from</span> <span class="nn">__future__</span> <span class="kn">import</span> <span class="n">absolute_import</span><span class="p">,</span> <span class="n">division</span><span class="p">,</span> <span class="n">print_function</span>
<span class="kn">import</span> <span class="nn">warnings</span>
<span class="kn">import</span> <span class="nn">utool</span> <span class="k">as</span> <span class="nn">ut</span>
<span class="kn">from</span> <span class="nn">Lasagne.lasagne</span> <span class="kn">import</span> <span class="n">layers</span>
<span class="kn">import</span> <span class="nn">theano</span>
<span class="kn">from</span> <span class="nn">theano</span> <span class="kn">import</span> <span class="n">tensor</span> <span class="k">as</span> <span class="n">T</span>  <span class="c1"># NOQA</span>

<span class="p">(</span><span class="nb">print</span><span class="p">,</span> <span class="n">rrr</span><span class="p">,</span> <span class="n">profile</span><span class="p">)</span> <span class="o">=</span> <span class="n">ut</span><span class="o">.</span><span class="n">inject2</span><span class="p">(</span><span class="vm">__name__</span><span class="p">)</span>


<div class="viewcode-block" id="l1"><a class="viewcode-back" href="../../wbia_cnn.html#wbia_cnn.lasagne_ext.l1">[docs]</a><span class="k">def</span> <span class="nf">l1</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">include_biases</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;custom should move to regulariztion.lasagne.l1</span>

<span class="sd">    NOT WORKING</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s1">&#39;not working&#39;</span><span class="p">)</span>
    <span class="k">with</span> <span class="n">warnings</span><span class="o">.</span><span class="n">catch_warnings</span><span class="p">():</span>
        <span class="c1"># warnings.simplefilter(&quot;ignore&quot;)</span>
        <span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s1">&#39;ignore&#39;</span><span class="p">,</span> <span class="s1">&#39;.*topo.*&#39;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">include_biases</span><span class="p">:</span>
            <span class="n">all_params</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">get_all_params</span><span class="p">(</span><span class="n">layer</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># all_params = layers.get_all_non_bias_params(layer)</span>
            <span class="n">all_params</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">get_all_params</span><span class="p">(</span><span class="n">regularizable</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="k">return</span> <span class="nb">sum</span><span class="p">(</span><span class="n">T</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">T</span><span class="o">.</span><span class="n">abs_</span><span class="p">(</span><span class="n">p</span><span class="p">))</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">all_params</span><span class="p">)</span></div>


<div class="viewcode-block" id="testdata_contrastive_loss"><a class="viewcode-back" href="../../wbia_cnn.html#wbia_cnn.lasagne_ext.testdata_contrastive_loss">[docs]</a><span class="k">def</span> <span class="nf">testdata_contrastive_loss</span><span class="p">():</span>
    <span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

    <span class="n">batch_size</span> <span class="o">=</span> <span class="mi">128</span>
    <span class="n">num_output</span> <span class="o">=</span> <span class="mi">256</span>
    <span class="n">half_size</span> <span class="o">=</span> <span class="n">batch_size</span> <span class="o">//</span> <span class="mi">2</span>
    <span class="n">quar_size</span> <span class="o">=</span> <span class="n">batch_size</span> <span class="o">//</span> <span class="mi">4</span>
    <span class="n">eigh_size</span> <span class="o">=</span> <span class="n">batch_size</span> <span class="o">//</span> <span class="mi">8</span>
    <span class="n">G</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">num_output</span><span class="p">)</span>
    <span class="n">G</span> <span class="o">=</span> <span class="n">G</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="nb">ord</span><span class="o">=</span><span class="mi">2</span><span class="p">)[:,</span> <span class="kc">None</span><span class="p">]</span>
    <span class="n">G</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">G</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">G</span><span class="p">[</span><span class="n">half_size</span><span class="p">]</span> <span class="o">=</span> <span class="n">G</span><span class="p">[</span><span class="n">half_size</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span>
    <span class="n">G</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="n">eigh_size</span><span class="p">:</span><span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
        <span class="n">G</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="n">eigh_size</span><span class="p">:</span><span class="mi">2</span><span class="p">]</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">eigh_size</span> <span class="o">/</span> <span class="mi">2</span><span class="p">,</span> <span class="n">num_output</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.00001</span>
    <span class="p">)</span>
    <span class="n">Y_padded</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)</span>
    <span class="n">Y_padded</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="n">half_size</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="n">Y_padded</span><span class="p">[</span><span class="n">quar_size</span> <span class="p">:</span> <span class="n">half_size</span> <span class="o">+</span> <span class="n">quar_size</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">Y_padded</span><span class="p">[</span><span class="o">-</span><span class="n">half_size</span><span class="p">:]</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
    <span class="k">return</span> <span class="n">G</span><span class="p">,</span> <span class="n">Y_padded</span></div>


<div class="viewcode-block" id="siamese_loss"><a class="viewcode-back" href="../../wbia_cnn.html#wbia_cnn.lasagne_ext.siamese_loss">[docs]</a><span class="k">def</span> <span class="nf">siamese_loss</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> <span class="n">Y_padded</span><span class="p">,</span> <span class="n">data_per_label</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">T</span><span class="o">=</span><span class="n">T</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Args:</span>
<span class="sd">        G : network output</span>
<span class="sd">        Y_padded: : target groundtruth labels (padded at the end with dummy values)</span>

<span class="sd">    References:</span>
<span class="sd">        https://www.cs.nyu.edu/~sumit/research/assets/cvpr05.pdf</span>
<span class="sd">        https://github.com/Lasagne/Lasagne/issues/168</span>

<span class="sd">    CommandLine:</span>
<span class="sd">        python -m wbia_cnn.lasagne_ext --test-siamese_loss</span>
<span class="sd">        # Train Network</span>
<span class="sd">        python -m wbia_cnn.train --test-pz_patchmatch --vtd --max-examples=16 --batch_size=128 --learning_rate .0000001</span>

<span class="sd">    CommandLine:</span>
<span class="sd">        python -m wbia_cnn.lasagne_ext --test-siamese_loss</span>

<span class="sd">    Example:</span>
<span class="sd">        &gt;&gt;&gt; # DISABLE_DOCTEST</span>
<span class="sd">        &gt;&gt;&gt; from wbia_cnn.lasagne_ext import *  # NOQA</span>
<span class="sd">        &gt;&gt;&gt; # numpy testing but in reality these are theano functions</span>
<span class="sd">        &gt;&gt;&gt; verbose = True</span>
<span class="sd">        &gt;&gt;&gt; G, Y_padded = testdata_contrastive_loss()</span>
<span class="sd">        &gt;&gt;&gt; T = np</span>
<span class="sd">        &gt;&gt;&gt; np.abs_ = np.abs</span>
<span class="sd">        &gt;&gt;&gt; avg_loss = siamese_loss(G, Y_padded, T=T)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">num_data</span> <span class="o">=</span> <span class="n">G</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">num_labels</span> <span class="o">=</span> <span class="n">num_data</span> <span class="o">//</span> <span class="n">data_per_label</span>
    <span class="c1"># Mark same genuine pairs as 0 and imposter pairs as 1</span>
    <span class="n">Y</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">Y_padded</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="n">num_labels</span><span class="p">]</span>
    <span class="n">Y</span> <span class="o">=</span> <span class="n">Y_padded</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="n">num_labels</span><span class="p">]</span>

    <span class="n">L1_NORMALIZE</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="k">if</span> <span class="n">L1_NORMALIZE</span><span class="p">:</span>
        <span class="c1"># L1-normalize the output of the network</span>
        <span class="n">G</span> <span class="o">=</span> <span class="n">G</span> <span class="o">/</span> <span class="n">T</span><span class="o">.</span><span class="n">abs_</span><span class="p">(</span><span class="n">G</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)[:,</span> <span class="kc">None</span><span class="p">]</span>

    <span class="c1"># Split batch into pairs</span>
    <span class="n">G1</span><span class="p">,</span> <span class="n">G2</span> <span class="o">=</span> <span class="n">G</span><span class="p">[</span><span class="mi">0</span><span class="p">::</span><span class="mi">2</span><span class="p">],</span> <span class="n">G</span><span class="p">[</span><span class="mi">1</span><span class="p">::</span><span class="mi">2</span><span class="p">]</span>

    <span class="k">if</span> <span class="n">T</span> <span class="ow">is</span> <span class="n">theano</span><span class="o">.</span><span class="n">tensor</span><span class="p">:</span>
        <span class="n">G1</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;G1&#39;</span>
        <span class="n">G2</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;G2&#39;</span>

    <span class="c1"># Energy of training pairs</span>
    <span class="k">if</span> <span class="kc">False</span><span class="p">:</span>
        <span class="c1"># Hack in a print</span>
        <span class="n">G_ellone</span> <span class="o">=</span> <span class="n">T</span><span class="o">.</span><span class="n">abs_</span><span class="p">(</span><span class="n">G</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">G_ellone_printer</span> <span class="o">=</span> <span class="n">theano</span><span class="o">.</span><span class="n">printing</span><span class="o">.</span><span class="n">Print</span><span class="p">(</span><span class="s1">&#39;ellone(G)&#39;</span><span class="p">)(</span><span class="n">G_ellone</span><span class="p">)</span>
        <span class="n">G_ellone</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;G_ellone&#39;</span>
        <span class="n">G_ellone_printer</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;G_ellone_printer&#39;</span>
        <span class="n">E</span> <span class="o">=</span> <span class="n">T</span><span class="o">.</span><span class="n">abs_</span><span class="p">((</span><span class="n">G1</span> <span class="o">-</span> <span class="n">G2</span><span class="p">))</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="p">(</span><span class="n">G_ellone</span> <span class="o">-</span> <span class="n">G_ellone_printer</span><span class="p">)[:,</span> <span class="kc">None</span><span class="p">]</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">E</span> <span class="o">=</span> <span class="n">T</span><span class="o">.</span><span class="n">abs_</span><span class="p">((</span><span class="n">G1</span> <span class="o">-</span> <span class="n">G2</span><span class="p">))</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">T</span> <span class="ow">is</span> <span class="n">theano</span><span class="o">.</span><span class="n">tensor</span><span class="p">:</span>
        <span class="n">E</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;E&#39;</span>

    <span class="c1"># Q is a constant that is the upper bound of E</span>
    <span class="k">if</span> <span class="n">L1_NORMALIZE</span><span class="p">:</span>
        <span class="n">Q</span> <span class="o">=</span> <span class="mi">2</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">Q</span> <span class="o">=</span> <span class="mi">20</span>
    <span class="c1"># Contrastive loss function</span>
    <span class="n">genuine_loss</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">Y</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="mi">2</span> <span class="o">/</span> <span class="n">Q</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">E</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span>
    <span class="n">imposter_loss</span> <span class="o">=</span> <span class="p">(</span><span class="n">Y</span><span class="p">)</span> <span class="o">*</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">Q</span> <span class="o">*</span> <span class="n">T</span><span class="o">.</span><span class="n">exp</span><span class="p">((</span><span class="o">-</span><span class="mf">2.77</span> <span class="o">*</span> <span class="n">E</span><span class="p">)</span> <span class="o">/</span> <span class="n">Q</span><span class="p">)</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">genuine_loss</span> <span class="o">+</span> <span class="n">imposter_loss</span>
    <span class="n">avg_loss</span> <span class="o">=</span> <span class="n">T</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">T</span> <span class="ow">is</span> <span class="n">theano</span><span class="o">.</span><span class="n">tensor</span><span class="p">:</span>
        <span class="n">loss</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;loss&#39;</span>
        <span class="n">avg_loss</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;avg_loss&#39;</span>
    <span class="k">return</span> <span class="n">avg_loss</span></div>


<div class="viewcode-block" id="freeze_params"><a class="viewcode-back" href="../../wbia_cnn.html#wbia_cnn.lasagne_ext.freeze_params">[docs]</a><span class="k">def</span> <span class="nf">freeze_params</span><span class="p">(</span><span class="n">layer</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    makes a layer untrainable</span>

<span class="sd">    References:</span>
<span class="sd">        https://github.com/Lasagne/Lasagne/pull/261</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">layer</span><span class="o">.</span><span class="n">params</span><span class="p">:</span>
        <span class="n">layer</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="n">param</span><span class="p">]</span><span class="o">.</span><span class="n">discard</span><span class="p">(</span><span class="s1">&#39;trainable&#39;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">layer</span></div>
</pre></div>

          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="../../index.html">wbia-cnn</a></h1>








<h3>Navigation</h3>
<p class="caption"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../wbia_cnn.html">wbia_cnn package</a></li>
</ul>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="../../index.html">Documentation overview</a><ul>
  <li><a href="../index.html">Module code</a><ul>
  <li><a href="../wbia_cnn.html">wbia_cnn</a><ul>
  </ul></li>
  </ul></li>
  </ul></li>
</ul>
</div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" />
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>$('#searchbox').show(0);</script>








        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2020, Wild Me.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 3.2.1</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.12</a>
      
    </div>

    

    
  </body>
</html>
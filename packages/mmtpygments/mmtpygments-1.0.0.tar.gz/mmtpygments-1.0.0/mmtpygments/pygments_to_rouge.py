# -*- coding: utf-8 -*-
"""
	Pygments to Rouge Lexer Converter
	~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

	:author: ComFreek <comfreek@outlook.com>
	:copyright: Copyright 2020 ComFreek
	:license: ISC, see LICENSE for details.
"""

import re

from pygments.lexer import RegexLexer

__all__ = ['convert_pygments_regex_lexer']

def convert_pygments_regex_lexer(regex_lexer, rouge_lexer_name, rouge_title, rouge_tag):
	ruby = ""
	ruby += """# -*- coding: utf-8 -*- #
# frozen_string_literal: true

# DO NOT EDIT - AUTOGENERATED
#
# This Rouge lexer file has been autogenerated from the Pygments lexer [1] by the script [2].
#
# [1]: {python_lexer_source}
# [2]: https://github.com/ComFreek/mmtpygments/blob/master/mmtpygments/pygments_to_rouge.py

module Rouge
	module Lexers
		class {class_name} < RegexLexer
			title '{title}'
			desc <<-DESC
{description}
DESC
			tag '{tag}'
			mimetypes {mimetypes}
			filenames {filenames}
""".format(
		python_lexer_source = regex_lexer.rouge_lexer_original_source,
		class_name = rouge_lexer_name,
		title = rouge_title,
		description = regex_lexer.rouge_lexer_description,
		tag = rouge_tag,
		mimetypes = ','.join(map(lambda s: "'{}'".format(s), regex_lexer.mimetypes)),
		filenames = ','.join(map(lambda s: "'{}'".format(s), regex_lexer.filenames))
	)

	for state, rules in regex_lexer.tokens.items():
		ruby += "\t\t\tstate :" + state + " do\n"
		for rule in rules:
			regex = rule[0]
			token_type = rule[1]
			if not type(token_type) is tuple:
				token_type = [token_type]
			
			next_state_type = None
			next_state_info = None

			if len(rule) == 3 and isinstance(rule[2], str):
				if rule[2] == '#pop':
					next_state_type = 'pop'
					next_state_info = 1
				elif rule[2].startswith("#pop:"): # pop the number of states given after colon
					number_of_states = int(rule[2][len("#pop:"):]) 

					next_state_type = 'pop'
					next_state_info = number_of_states
				else:
					next_state_type = 'push'
					next_state_info = [rule[2]] # push a single state
			elif len(rule) == 3 and isinstance(rule[2], tuple):
				# rule[2] contains a list of states to be pushed
				next_state_type = 'push'
				next_state_info = rule[2]
			
			ruby += format_ruby_rule(regex, token_type, next_state_type, next_state_info, indentation="\t\t\t\t", regex_python_flags=regex_lexer.flags)
		ruby += "\t\t\tend\n"
	
	ruby += "\t\tend\n"
	ruby += "\tend\n"
	ruby += "end\n"
	
	return ruby

def format_ruby_regex(regex, python_flags):
	ruby = "%r/" + regex + "/"
	if re.IGNORECASE in python_flags:
		ruby += "i"

	# Ruby cannot distinguish between these flags
	if re.MULTILINE in python_flags or re.DOTALL in python_flags:
		ruby += "m"
	
	return ruby

# input is Pygments token type
def format_ruby_single_token_type(token_type):
	token_type = str(token_type).replace('Token.','').replace('.','::')
	
	# Post-hoc fixes
	# TODO: provide a customizable option to deal with such custom token types
	if token_type == 'Literal::URI' or token_type.startswith('MMT'):
		token_type = 'Text'
	
	return token_type

def format_ruby_token_types(token_types):
	token_types = list(map(format_ruby_single_token_type, token_types))

	return ('groups ' if len(token_types) > 1 else 'token ' )+ ','.join(token_types)

def format_ruby_next_state(next_state_type, next_state_info, indentation):
	if next_state_type == 'push':
		return '\n'.join(map(
			lambda new_state: '{}push :{}'.format(indentation, new_state),
			next_state_info
		)) + '\n'
	elif next_state_type == 'pop':
		# next_state_info is number of states to be popped
		return '{}pop!({})\n'.format(indentation, next_state_info)
	else:
		return '' # Do nothing

def format_ruby_rule(regex, token_types, next_state_type, next_state_info, indentation = "", regex_python_flags = []):
	return "{}rule {} do\n{}\n{}{}end\n".format(
		indentation,
		format_ruby_regex(regex, regex_python_flags),
		indentation + '\t' + format_ruby_token_types(token_types),
		format_ruby_next_state(next_state_type, next_state_info, indentation + '\t'),
		indentation
	)